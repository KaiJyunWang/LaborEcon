\documentclass[12pt]{article}
\input{prefix.tex}%
\input{symbols.tex}

\title{
    A Brief Introduction to the Fundamental Methods in Dynamic 
    Programming
    }

\author{%
   Kai-Jyun Wang
   \thanks{Department of Economics; National Taiwan University. 
   Email: \url{b11303072@ntu.edu.tw}.}
}

\date{\today}

\begin{document}
\setstretch{1.2}

\maketitle

\section*{Foreword}
This document aims at providing mathematical details for fundamental 
methods used to solve dynamic programming problems. Three methods 
are covered: value function iteration (VFI), envelope condition method 
(ECM), and policy function iteration (PFI). For implementation in 
Julia, please refer to Sargent's fantastic 
\href{https://julia.quantecon.org/dynamic_programming/optgrowth.html}
{website}. This document serves as a supplement to the website.

\tableofcontents

\section{Optimal Growth Model}
In this capter, we introduce an optimal growth model. The model is 
going to be our working example for VFI. 

Consider an agent who seeks to maximize his lifetime expected utility. 
The agent's problem is to choose his future path of consumption $c_t$ 
and capital stock $k_{t+1}$, subject to the constraint: 
\begin{equation}\eqlab{constraint}
    c_t + k_{t+1} \leq y_t,
\end{equation} 
where both $c_t$ and $k_{t+1}$ are non-negative. $y_t$ is the agent's 
income at time $t$, which follows the law of motion: 
\begin{equation}\eqlab{production}
    y_t = z_t f(k_t),\quad z_t \overset{iid}{\sim} \phi,
\end{equation}
where $z_t$ is a random variable that follows a positively supported 
distribution $\phi$. $f(k_t)$ is the production function. 

\begin{assumption}
    The production function $f(k_t)$ is continuous and increasing in 
    $k_t$.
\end{assumption}

The agent's optimization problem is given by: 
\begin{equation}
    v(y_t) = \max_{c_t} \E_0\sbrc{\sum_{t=0}^{\infty} \beta^t u(c_t)},
\end{equation}
subject to the constraints \eqref{constraint} and \eqref{production},
where $\beta \in (0, 1)$ is the discount factor, and $u(c_t)$ is the 
utility flow in each period. $v(y_t)$ is called the \textbf{value 
function} and $y_t$ is called the \textbf{state variable} of $v$. We 
further take two assumptions on $u(\cdot)$ and $v(\cdot)$.

\begin{assumption}
    The utility function $u(c_t)$ is continuous and increasing in 
    $c_t$.
\end{assumption}

Note that by this assumption, the inequality in \eqref{constraint} 
is replaced by an equality since if $c_t + k_{t+1}$ is strictly less 
than $y_t$, the agent can always increase $c_t$ to improve the 
utility. 

\begin{assumption}
    The value function $v(y_t)$ is bounded.
\end{assumption}

Note that we may also write value function as follows. 
\begin{equation}
    \begin{split}
        v(y_0) 
        &= \max_{c_t} \E_0\sbrc{\sum_{t=0}^{\infty} \beta^t u(c_t)}\\
        &= \max_{c_t} \E_0\sbrc{u(c_0) + \beta\sum_{t=1}^{\infty} \beta^{t-1} u(c_t)}\\
        &= \max_{c_t} u(c_0) + \beta\E_0\sbrc{\sum_{t=0}^{\infty} \beta^{t} u(c_{t+1})}\\ 
        &= \max_{c_0} u(c_0) + \beta\E_0\sbrc{v(y_1)}\\
        &= \max_{c_0} u(c_0) + \beta\int v(z_1f(y_0-c_0))\phi(dz_1).
    \end{split}
\end{equation}
The form is called the \textbf{Bellman equation}. It is a functional 
equation regarding $v$. Note that the true value function would solve 
this functional equation. The Bellman equation approach 
has a significant advantage compared to the traditional method of 
Lagrange multiplier; the Bellman equation approach transforms an 
infinite horizon problem into a two-period problem, and also deals 
with the uncertainty. However, there is a clear drawback: How to find 
$v$? 

\section{Value Function Iteration} 
In this section, we provide mathematical details for value function 
iteration. We begin by introducing some 
fundamental concepts in analysis. 

\begin{definition}
    A \textbf{metric space} is a pair $(X, d)$, where $X$ is a set 
    and $d: X \times X \to \R$ is a function that satisfies the 
    following properties: 
    \begin{thmenum}
        \item $d(x, y) \geq 0$ for all $x, y \in X$; $d(x, y) = 0$ 
        if and only if $x = y$.
        \item $d(x, y) = d(y, x)$ for all $x, y \in X$.
        \item $d(x, z) \leq d(x, y) + d(y, z)$ for all $x, y, z \in X$.
    \end{thmenum}
    $d$ is called a \textbf{metric} (\textbf{distance}) on $X$.
\end{definition}

\begin{definition}
    A sequence $\set{x_n}$ in a metric space $(X, d)$ is said to be 
    converge to $x \in X$ if for every $\epsilon > 0$, there exists 
    $N \in \N$ such that $d(x_n, x) < \epsilon$ for all $n \geq N$.
\end{definition}

\begin{definition}
    A sequence $\set{x_n}$ in a metric space $(X, d)$ is said to be 
    \textbf{Cauchy} if for every $\epsilon > 0$, there exists $N \in 
    \N$ such that $d(x_n, x_m) < \epsilon$ for all $n, m \geq N$.
\end{definition}

\begin{definition}
    A metric space $(X, d)$ is said to be \textbf{complete} if every 
    Cauchy sequence in $X$ converges to a point in $X$.
\end{definition}

\begin{remark}
    $\R^n$ is a complete metric space under the Euclidean metric $d(x,y) = 
    \sqrt{\sum_{i=1}^{n}(x_i-y_i)^2}$.
\end{remark}

\begin{definition}
    A normed space $X$ is a vector space with scalar field $\R$
    equipped with a norm $\norm{\cdot}$, satisfying that 
    \begin{thmenum}
        \item $\norm{x} \geq 0$ for all $x\in X$; $\norm{x} = 0$ if 
        and only if $x = 0$.
        \item $\norm{ax} = \abs{a}\norm{x}$ for all $a\in\R$ and $x\in X$.
        \item $\norm{x+y} \leq \norm{x} + \norm{y}$ for all $x, y\in X$.
    \end{thmenum}
\end{definition}

\begin{remark}
    The scalar field $\R$ can be replaced by other fields, but 
    for our purpose, we only consider $\R$.
\end{remark}

\begin{remark}
    The norm induces a metric $d(x, y) = \norm{x-y}$. In fact, 
    the Euclidean norm $\norm{x} = \sqrt{\sum_{i=1}^{n}x_i^2}$ 
    induces the Euclidean metric. For this reason, a normed 
    space is automatically a metric space and the metric is 
    defined by its norm.
\end{remark}

\begin{definition}
    $B(X)$ is the set of all real-valued bounded continuous functions 
    defined on $X$.
\end{definition}

\begin{proposition}
    $B(X)$ is a complete metric space under the supremum norm
    $\ds \norm{f} = \sup_{x \in X} \abs{f(x)}$.
\end{proposition}
\begin{pf}
    Let $\set{f_n}$ be a Cauchy sequence in $B(X)$. For each $x \in 
    X$, define $f(x) = \lim_{n\to\infty} f_n(x)$. The limit exists 
    since $\set{f_n(x)}$ is a Cauchy sequence in $\R$. We claim that
    $f\in B(X)$. First, $f$ is bounded since for each $x \in X$, 
    there exists $N$ such that $\abs{f_n(x) - f_m(x)} < \epsilon$ 
    for all $n, m \geq N$. Letting $m = N$ and $n\to\infty$ yields 
    that $\abs{f(x) - f_N(x)}\leq \epsilon$. Hence, $\abs{f(x)} \leq 
    \abs{f_N(x)} + \epsilon$ for all $x \in X$. Second, $f$ is 
    continuous since for each $x \in X$ and $\epsilon > 0$, we 
    may pick $\delta > 0$ such that $\abs{f_N(x) - f_N(y)} < 
    \epsilon$ for all $y \in X$ with $d(x, y) < \delta$. Hence, 
    $\abs{f(x) - f(y)} \leq \abs{f(x) - f_N(x)} + \abs{f_N(x) - 
    f_N(y)} + \abs{f_N(y) - f(y)} < 3\epsilon$ for all $y \in X$ 
    with $d(x, y) < \delta$. Since $\epsilon$ is arbitrary, $f$ 
    is indeed continuous and hence $f\in B(X)$. This completes 
    the proof.
\end{pf}

\begin{definition}
    An operator $T: X \to X$ is called a \textbf{contraction} 
    if there exists $\alpha \in (0, 1)$ such that $d(T(x), T(y)) \leq 
    \alpha d(x, y)$ for all $x, y \in X$.
\end{definition}

\begin{theorem}[Contraction Mapping Theorem]
    Let $(X, d)$ be a complete metric space and $T: X \to X$ be a 
    contraction mapping with contraction factor $\alpha \in (0, 1)$. 
    Then $T$ has an unique fixed point $x^* \in X$. That is, $Tx^* 
    = x^*$. Furthermore, for any $x_0\in X$, the sequence $\set{x_n}$ 
    defined by $x_{n+1} = Tx_n$ converges to $x^*$.
\end{theorem}
\begin{pf}
    For each $x_0 \in X$, we define $x_n = T^n(x_0)$. Then 
    \begin{equation}
        d(x_{n+1}, x_n) = d(T^{n+1}(x_0), T^n(x_0)) \leq \alpha^n 
        d(x_1, x_0)\to 0 \quad \text{as } n\to\infty.
    \end{equation}
    Hence, $\set{x_n}$ is a Cauchy sequence. Since $X$ is complete, 
    $\set{x_n}$ converges to some $x^* \in X$. Next, suppose both 
    $x^*$ and $y^*$ are fixed points of $T$. Then 
    \begin{equation}
        d(x^*, y^*) = d(T(x^*), T(y^*)) \leq \alpha d(x^*, y^*) 
        < d(x^*, y^*),
    \end{equation}
    posing a contradiction. Therefore, $x^*$ is unique.  
\end{pf}

\begin{theorem}[Blackwell's Theorem]
    Suppose $T: B(X) \to B(X)$ satisfies the following properties: 
    \begin{thmenum}
        \item $T$ is monotone, i.e., $f \leq g$ implies $Tf \leq Tg$.
        \item There exists $\alpha\in (0,1)$ such that for any 
        $c\in \R_+$, $T(f+a) \leq Tf + \alpha c$.
    \end{thmenum}
    Then $T$ is a contraction.
\end{theorem}
\begin{pf}
    Suppose $f, g \in B(X)$ and $c\in\R_+$ satisfy the conditions 
    (a) and (b). Then notice that
    \begin{equation}
        g \leq f + \norm{f-g}.
    \end{equation}
    Thus we have 
    \begin{equation}
        Tg \leq T(f + \norm{f-g}) \leq Tf + \alpha\norm{f-g}.
    \end{equation}
    Rearranging the terms and taking the norm yiels the 
    desired result.
\end{pf}

We now turn back to the Bellman equation. 

\begin{definition}
    The \textbf{Bellman operator} $T: v \mapsto Tv$ is defined by 
    \begin{equation}
        Tv(y) = \max_{c} u(y) + \beta\int v(zf(y-c))\phi(dz).
    \end{equation}
\end{definition}
\begin{remark}
    The solution to the Bellman equation is the fixed point of the 
    Bellman operator $T$.
\end{remark}

\begin{corollary}
    The Bellman operator $T$ is a contraction.
\end{corollary}
\begin{pf}
    Left as an exercise.
\end{pf}

\begin{comment}
\begin{pf}
    We are going to check the conditions in Blackwell's Theorem are 
    satisfied. First, if $v\leq w$, $v,w\in B(X)$, let $c_v$ and 
    $c_w$ be the optimal consumption for $v$ and $w$, respectively. 
    Then 
    \begin{equation}
        \begin{split}
            Tv(y) 
            &= u(c_v) + \beta\int v(zf(y-c_v))\phi(dz)\\
            &\leq u(c_v) + \beta\int w(zf(y-c_v))\phi(dz)\\
            &\leq u(c_w) + \beta\int w(zf(y-c_w))\phi(dz) = Tw(y).
        \end{split}
    \end{equation} 
    Thus the monotonicity is satisfied. Second, for any $c\in\R_+$, 
    \begin{equation}
        \begin{split}
            T(v+c)(y) 
            &= u(c) + \beta\int v(zf(y-c))\phi(dz)\\
            &\leq u(c) + \beta\int v(zf(y-c))+c \phi(dz)
            = Tv(y) + \alpha c.
        \end{split}
    \end{equation}
    This completes the proof.
\end{pf}
\end{comment}

Since $B(X)$ is a complete metric space and $T$ is a contraction 
operator on it, by the contraction mapping theorem, $T$ has an 
unique fixed point. This fixed point is the solution to the 
Bellman equation. Also, the proof of the contraction mapping 
theorem reveals a numerical algorithm to find the fixed point:
\begin{thmenum}
    \item Start with a guess $v_0\in B(X)$.
    \item Apply the Bellman operator $T$ to $v_0$ to get $v_1 = 
    Tv_0$. 
    \item Compare $v_1$ with $v_0$. If they are close enough, 
    stop; otherwise, set $v_0 = v_1$ and repeat step 2.
\end{thmenum} 
The algorithm is called the \textbf{value function iteration}. 

The value function iteration is one of the most popular methods 
to solve dynamic programming problems. One may observe that in the 
finite-horizon case, the value function iteration is equivalent to 
the backward induction. 

\section{Envelope Condition Method}
In this section, we introduce the envelope condition method. We 
begin by adding a few assumptions to the optimal growth model.

\begin{assumption}
    $u(\cdot), f(\cdot)\in C^\infty$ are both strictly concave.
\end{assumption}

\begin{assumption}
    $u(0) = f(0) = 0$.
\end{assumption}

\begin{assumption}
    $u(\cdot),f(\cdot)$ satisfies the Inada conditions: 
    \begin{equation}
        \begin{aligned}
            \lim_{c\to 0} u'(c) = \infty, \quad & \lim_{c\to \infty} u'(c) = 0,\\
            \lim_{k\to 0} f'(k) = \infty, \quad & \lim_{k\to \infty} f'(k) = 0.
        \end{aligned}
    \end{equation}
\end{assumption}

\begin{definition}
    A function $c^*: \R_+ \to \R_+$ is called the 
    \textbf{optimal policy} if 
    \begin{equation}
        c^*(y) = \argmax_{c} u(c) + \beta\int v^*(zf(y-c))\phi(dz),
    \end{equation}
    where $v^*$ is the value function.
\end{definition}

Following this definition, several properties are derived. 

\begin{proposition}
    $c^*$ satisfies the following:
    \begin{thmenum}
        \item $c^*$ is unique.
        \item $c^*$ is continuous and strictly increasing. 
        \item $c^*(y)\in (0,y)$ for any $y>0$. 
        \item $(v^*)'(y) = (u'\circ c^*)(y)$.
    \end{thmenum}
\end{proposition}
\begin{pf}
    (a), (b) and (c) are omitted. For (d), one may write 
    \begin{equation}
        v^*(y) = \max_k u(y-k) + \beta\int v^*(zf(k))\phi(dz).
    \end{equation}
    Differentiating with respect to $y$ and evaluating at the 
    maximum yields 
    \begin{equation}
        (v^*)'(y) = u'(c^*(y)).
    \end{equation}
\end{pf}

\begin{remark}
    The last property is called the \textbf{envelope condition}.
\end{remark}

Now, by the first order condition, we have 
\begin{equation}
    \begin{split}
        u'(c^*(y)) &= \beta\int (v^*)'(zf(y-c^*(y)))zf'(y-c^*(y))\phi(dz)\\
        &= \beta\int (u'\circ c^*)(zf(y-c^*(y)))zf'(y-c^*(y))\phi(dz).
    \end{split}
\end{equation}
Our goal is to find $c^*$ solving the above functional 
equation. We first define the set where $c^*$ lies. 
\begin{definition}
    \begin{equation}
        \Sigma \coloneqq \Set{\sigma}{\sigma:y\mapsto \sigma(y)\in(0,y)
        \text{ is continuous, strictly increasing.}}
    \end{equation}
\end{definition}
And an operator on it.
\begin{definition}
    $K: \Sigma \to \Sigma$ with $K\sigma$ defined by the solution $c$ of 
    the following functional equation:
    \begin{equation}
        u'(c) = \beta\int (u'\circ \sigma)(zf(y-c))zf'(y-c)\phi(dz).
    \end{equation}
\end{definition}

A careful reader may question whether $K$ is 
well-defined. The following proposition addresses 
this issue.
\begin{proposition}
    $K$ is well-defined.
\end{proposition}
\begin{pf}
    To show that $K$ is well-defined, we need to show that 
    the functional equation has an unique solution lying in 
    $\Sigma$ given any $\sigma\in\Sigma$. 

    First, observe that the left hand side of the equation 
    is strictly decreasing in $c$ with the value approaching 
    $\infty$ as $c\to 0$ and approaching $0$ as $c\to \infty$. 
    The right hand side is strictly increasing in $c$ with the 
    value approaching $0$ as $c\to 0$ and approaching $\infty$ 
    as $c\to y$. Hence, the equation has a solution by the 
    intermediate value theorem. The strict monotonicity further 
    guarantees the uniqueness of the solution.

    Next, we have to show that the solution lies in $\Sigma$. 
    By previous discussion, the solution is interior. Also, 
    it is strictly increasing since given any $c$, the right 
    hand side is strictly decreasing in $y$, and hence the 
    solution must be strictly increasing. The last piece is 
    the continuity. This is guaranteed by the continuity of 
    $u', f, f'$ and $\sigma$.
\end{pf}
Having shown that $K$ is well-defined, we are now in a position 
to examine the convergence of the operator. The operator $K$ has, 
in fact, a tight connection with the Bellman operator $T$. 
We are going to see the connection by introducing the following 
mapping. 
\begin{definition}
    Let $\F = \Set{v:\R_+ \to\R_+}{v(0) = 0, v'(y)>u'(y), 
    \text{ $v$ is strictly concave and differentiable.}}$. 
    Define $\varphi:\F \to\Sigma$ with 
    $v\mapsto \varphi v = (u')^{-1}\circ v'$.
\end{definition}
\begin{proposition}
    $\varphi$ is a bijection.
\end{proposition}
\begin{pf}
    We first check that $\varphi$ is well-defined. By 
    assumption, $u'$ is strictly decreasing and continuous; 
    $u'$ is thus a bijection and hence so is $(u')^{-1}$. Note 
    that $u'$ maps $(0, \infty)$ to $(0, \infty)$, and so 
    does $v'$. Also, for every $v\in\F$, $v'$ is strictly 
    decreasing and continuous, which implies that $\varphi v$ 
    is strictly increasing and continuous with range 
    $(0, \infty)$. Furthermore, since $v'>u'$, $\varphi v(y) 
    = ((u')^{-1}\circ v')(y)<((u')^{-1}\circ u')(y) = y$. It 
    follows that $\sigma\coloneqq\phi v\in\Sigma$. 

    Next, we show that $\varphi$ is a bijection. Fix 
    $\sigma\in\Sigma$, let 
    \begin{equation}
        v(y) = \int_{0}^{y} u'(\sigma(x)) dx \in \F.
    \end{equation}
    Then $\varphi v = (u')^{-1}(u'(\sigma(y))) = \sigma(y)$. 
    Thus $\varphi$ is surjective. Besides, if $\varphi v = 
    \varphi w$, then $(u')^{-1}\circ v' = (u')^{-1}\circ w'$ 
    and thus $v' = w'$. Since $v(0) = w(0) = 0$, $v = w$. 
    Hence $\varphi$ is injective. This completes the proof. 
\end{pf}

\begin{theorem}
    The diagram \\
    \begin{center}
        \vspace{-1cm}
        \begin{tikzcd}
            \F \arrow[r, "T"] \arrow[d, "\varphi"]
            & \F \arrow[d, "\varphi"] \\
            \Sigma \arrow[r,"K"]
            & \Sigma
        \end{tikzcd}
    \end{center}
    commutes. That is, for any $v\in\F$, $\varphi Tv 
    = K\varphi v$.
\end{theorem}
\begin{pf}
    For any $v\in\F$, by the envelope theorem, 
    $(Tv)'(y) = u'(\sigma(y))$, where $\sigma$ solves 
    \begin{equation}
        u'(\sigma(y)) = \beta\int (u'\circ \sigma)(zf(y-\sigma(y)))zf'(y-\sigma(y))\phi(dz).
    \end{equation}
    This implies that
    \begin{equation}
        \varphi Tv = ((u')^{-1}\circ u')(\sigma(y)) = \sigma.
    \end{equation}
    On the other hand, $K\varphi v(y)$ is the $\sigma$ 
    that solves 
    \begin{equation}
        \begin{split}
            u'(\sigma(y)) 
            &= \beta\int (u'\circ (\varphi v))(zf(y-\sigma(y)))zf'(y-\sigma(y))\phi(dz) \\
            &= \beta\int (u'\circ ((u')^{-1}\circ v'))(zf(y-\sigma(y)))zf'(y-\sigma(y))\phi(dz) \\ 
            &= \beta\int v'(zf(y-\sigma(y)))zf'(y-\sigma(y))\phi(dz).
        \end{split}
    \end{equation}
    The two $\sigma$ coincide, and hence the diagram commutes.
\end{pf}
\begin{corollary}
    The sequence of policies 
    $\set{\sigma, K\sigma, K^2\sigma,\ldots}$ 
    converges to the optimal policy $c^*$.
\end{corollary}
\begin{pf}
    With the above theorem, we may write $K^n = 
    \varphi T^n \varphi$. Since $T$ is a contraction, 
    $T^n\varphi^{-1}\sigma$ converges to the fixed point of $T$, which 
    is $v^*$. Thus $K^n\sigma$ converges to $c^*$.
\end{pf}

The above result not only shows the convergence of the
operator $K$ but also tells us that the convergent rate 
is the same as the Bellman operator $T$. 

However, in practice, the envelope condition method tends 
to be more efficient than the value function iteration. 
One of the reason is that the curvature of the policy 
function tends to be smaller than the value function. 
While using linear interpolation to approximate the 
value off the grid points, the error is smaller for
the policy function. 

Another important reason is that the envelope condition 
method is often combined with the endogenous grid method. 
The computationally expensive part of the envelope 
condition method is to solve the functional equation. 
This is because of the appearance of $c$ on both sides. 
The endogenous grid method solves this issue by putting 
grids on $k$ instead of $y$. By doing so, in every step, 
one only needs to evaluate the integral on the right hand 
side and then apply the inverse of $u'$ to get the 
updated policy function, which is much faster.

\section{Policy Function Iteration}
The last method we are going to introduce is the policy 
function iteration, also known as the Howard's policy 
improvement algorithm. 
\end{document}